{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54a4529a",
   "metadata": {},
   "source": [
    "# Deep Learning Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb160ca",
   "metadata": {},
   "source": [
    "This project focuses on developing a classifier using machine learning techniques, incorporating libraries such as TensorFlow and scikit-learn. TensorFlow is employed to build and train machine learning models, while scikit-learn's support vector machine (SVM) module is harnessed for this particular task. The classifier combines convolutional neural networks (CNNs) and support vector machines for classification. The CNN comprises nine layers, including Conv2D, MaxPooling2D, Flatten, and Dense layers, determined through iterative experimentation for optimal accuracy and efficiency. Hyperparameters like batch size and learning rate are similarly fine-tuned through experimentation. The Dogs and Cats dataset, containing images of dogs and cats, is utilized for training, validation, and testing. The classifier's objective is to accurately distinguish between dog and cat images, aided by the inclusion of a linear SVM for the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da4c6bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required libraries\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, preprocessing\n",
    "from sklearn import svm, metrics\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import optimizers\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "239f964e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing directory\n",
    "os.chdir('D:\\\\Python\\\\Datafolder\\\\Cats and Dogs images\\\\archive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e700c0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the input shape and number of classes\n",
    "input_shape = (150, 150, 3)\n",
    "num_classes = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291064c0",
   "metadata": {},
   "source": [
    "### Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e29d64b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the variables\n",
    "train_datagen = preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "validation_datagen = preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = preprocessing.image.ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c943c7cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1024 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Training dataset\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'train',\n",
    "        target_size=input_shape[:2],\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b56cf63b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 512 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Validation dataset\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "        'valid',\n",
    "        target_size=input_shape[:2],\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "060a90de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 128 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "# Testing dataset\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        'test',\n",
    "        target_size=input_shape[:2],\n",
    "        batch_size=32,\n",
    "       class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e3c17c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset shape\n",
      "(32, 150, 150, 3)\n",
      "(32, 2)\n",
      "Validation Dataset shape\n",
      "(32, 150, 150, 3)\n",
      "(32, 2)\n",
      "Testing Dataset shape\n",
      "(32, 150, 150, 3)\n",
      "(32, 1)\n"
     ]
    }
   ],
   "source": [
    "# Shape of the datasets\n",
    "batch1 = next(train_generator)\n",
    "print('Training Dataset shape')\n",
    "print(batch1[0].shape) # shape of input data\n",
    "print(batch1[1].shape) # shape of labels/targets\n",
    "batch2 = next(validation_generator)\n",
    "print('Validation Dataset shape')\n",
    "print(batch2[0].shape) \n",
    "print(batch2[1].shape) \n",
    "batch3 = next(test_generator)\n",
    "print('Testing Dataset shape')\n",
    "print(batch3[0].shape) \n",
    "print(batch3[1].shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "749b63f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input shape and number of classes for the model\n",
    "input_shape = (150, 150, 3)\n",
    "num_classes = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbfbaf24",
   "metadata": {},
   "source": [
    "### Defining the model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e1c94ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the deep learning model\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(16, (3, 3), activation='relu', input_shape=input_shape))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c5493e8f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_54 (Conv2D)          (None, 148, 148, 16)      448       \n",
      "                                                                 \n",
      " max_pooling2d_54 (MaxPoolin  (None, 74, 74, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_55 (Conv2D)          (None, 72, 72, 32)        4640      \n",
      "                                                                 \n",
      " max_pooling2d_55 (MaxPoolin  (None, 36, 36, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_56 (Conv2D)          (None, 34, 34, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_56 (MaxPoolin  (None, 17, 17, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_15 (Flatten)        (None, 18496)             0         \n",
      "                                                                 \n",
      " dense_30 (Dense)            (None, 64)                1183808   \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,207,522\n",
      "Trainable params: 1,207,522\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "dbd96e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer= keras.optimizers.Adam(learning_rate=0.001), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5cc5403",
   "metadata": {},
   "source": [
    "### Training the deep learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ff3cc1e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "32/32 [==============================] - 19s 567ms/step - loss: 0.7072 - accuracy: 0.5020 - val_loss: 0.6837 - val_accuracy: 0.5156\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 18s 554ms/step - loss: 0.6653 - accuracy: 0.6045 - val_loss: 0.6579 - val_accuracy: 0.5703\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 18s 559ms/step - loss: 0.6076 - accuracy: 0.6660 - val_loss: 0.6135 - val_accuracy: 0.6641\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 18s 561ms/step - loss: 0.5392 - accuracy: 0.7373 - val_loss: 0.5767 - val_accuracy: 0.7031\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 20s 632ms/step - loss: 0.4990 - accuracy: 0.7607 - val_loss: 0.5933 - val_accuracy: 0.7148\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 18s 575ms/step - loss: 0.4468 - accuracy: 0.8008 - val_loss: 0.6123 - val_accuracy: 0.7422\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 18s 569ms/step - loss: 0.3735 - accuracy: 0.8330 - val_loss: 0.7414 - val_accuracy: 0.6680\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 20s 620ms/step - loss: 0.3310 - accuracy: 0.8564 - val_loss: 0.7731 - val_accuracy: 0.6875\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 18s 559ms/step - loss: 0.2861 - accuracy: 0.8770 - val_loss: 0.8179 - val_accuracy: 0.6719\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 18s 567ms/step - loss: 0.2190 - accuracy: 0.9131 - val_loss: 0.7888 - val_accuracy: 0.7070\n"
     ]
    }
   ],
   "source": [
    "# Training the deep learning model\n",
    "history = model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=512 // 16,\n",
    "        epochs=10,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=128 // 16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d1902d",
   "metadata": {},
   "source": [
    "### Model Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "16a640c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 2s 537ms/step - loss: 0.8904 - accuracy: 0.7500\n",
      "Test Loss: 0.8903511762619019, Test Accuracy: 0.75\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the trained model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(test_generator)\n",
    "\n",
    "print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df819149",
   "metadata": {},
   "source": [
    "#### Extracting the features from the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "0afd2e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the features from the validation set\n",
    "validation_features = model.predict(validation_generator)\n",
    "validation_labels = validation_generator.classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48704797",
   "metadata": {},
   "source": [
    "## Training the SVM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "8a0904d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearSVC()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearSVC</label><div class=\"sk-toggleable__content\"><pre>LinearSVC()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearSVC()"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the SVM model using the features extracted from the validation set\n",
    "svm_model = svm.LinearSVC()\n",
    "svm_model.fit(validation_features, validation_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d285ef",
   "metadata": {},
   "source": [
    "#### Extracting the features from the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c9a67c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the features from the test set\n",
    "test_features = model.predict(test_generator)\n",
    "test_labels = test_generator.classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e033dd3",
   "metadata": {},
   "source": [
    "### Evaluating the SVM model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9089447a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.578125, Precision: 0.0, Recall: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the SVM model on the test set\n",
    "test_predictions = svm_model.predict(test_features)\n",
    "accuracy = metrics.accuracy_score(test_labels, test_predictions)\n",
    "precision = metrics.precision_score(test_labels, test_predictions, zero_division=1)\n",
    "recall = metrics.recall_score(test_labels, test_predictions, zero_division=1)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}, Precision: {precision}, Recall: {recall}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac7099e",
   "metadata": {},
   "source": [
    "## The End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
